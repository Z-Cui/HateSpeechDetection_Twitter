{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "# BERT Fine-Tuning Tutorial with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2937,
     "status": "ok",
     "timestamp": 1588967246055,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "DEfSbAA4QHas",
    "outputId": "0d02a86a-4de8-44d9-c5b4-e811bd0be1d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2898,
     "status": "ok",
     "timestamp": 1588967246058,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "b0d83e90-bf61-4741-9289-e8b8172a7fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ElsnSNUridI"
   },
   "source": [
    "Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8638,
     "status": "ok",
     "timestamp": 1588967251829,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "87021ef5-0244-4dab-94bc-8cbb011db834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "# 2. Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8577,
     "status": "ok",
     "timestamp": 1588967251830,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "_UkeC7SG2krJ",
    "outputId": "5be5c75b-a66c-48a5-dcd4-520c7a0be749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 31,962\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>10319</td>\n",
       "      <td>10320</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user scary that it's not that long ago!</td>\n",
       "      <td>scary that it is not that long ago!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23048</th>\n",
       "      <td>23048</td>\n",
       "      <td>23049</td>\n",
       "      <td>0</td>\n",
       "      <td>we got buzz!   #kids #toys #disney#tsumtsums</td>\n",
       "      <td>we got buzz! #kids #toys #disney #tsumtsums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>1969</td>\n",
       "      <td>1970</td>\n",
       "      <td>0</td>\n",
       "      <td>@user its like they learned from ff13's super...</td>\n",
       "      <td>its like they learned from ff13's super linea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>6758</td>\n",
       "      <td>6759</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thriving. #i_am #positive #affirmation</td>\n",
       "      <td>i am thriving. #i_am #positive #affirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>14049</td>\n",
       "      <td>14050</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #spoty perhaps the #murrayhaters would b...</td>\n",
       "      <td>#spoty perhaps the #murrayhaters would be hap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ...                                      cleaned_tweet\n",
       "10319       10319  ...               scary that it is not that long ago! \n",
       "23048       23048  ...       we got buzz! #kids #toys #disney #tsumtsums \n",
       "1969         1969  ...   its like they learned from ff13's super linea...\n",
       "6758         6758  ...       i am thriving. #i_am #positive #affirmation \n",
       "14049       14049  ...   #spoty perhaps the #murrayhaters would be hap...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"train_E6oV3lV_cleaned.csv\")\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KATu07yHxF_Y"
   },
   "source": [
    "### Balance the dataset \n",
    "partition of 2 classes from imbalanced to 50%:50%\n",
    "- calculate the count of samples in class 1, let the count as N\n",
    "- select all class 1 samples, let the sampled dataset as df_class1\n",
    "- randomly select 2N samples in class 0, let the sampled dataset as df_class0\n",
    "- concatenate df_class0 and 2 copies of df_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8550,
     "status": "ok",
     "timestamp": 1588967251832,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "6HTEjCj8vo3j",
    "outputId": "ebacb478-3c2a-4fe0-85f3-448a1e65f067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of balanced training sentences: 8,968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_balanced = [ df.loc[df.label == 0].sample(10), df.loc[df.lable == 1].sample(10) ]\n",
    "df_class1 = df.loc[df.label == 1]\n",
    "N = df_class1.shape[0]\n",
    "df_class0 = df.loc[df.label == 0].sample(2 * N)\n",
    "\n",
    "df_balanced = [df_class0, df_class1, df_class1]\n",
    "df = pd.concat(df_balanced)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of balanced training sentences: {:,}\\n'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuE5BqICAne2"
   },
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.cleaned_tweet.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "# 3. Tokenization & Input Formatting\n",
    "\n",
    "In this section, we'll transform our dataset into the format that BERT can be trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8kEDRvShcU5"
   },
   "source": [
    "## 3.1. Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWOPOyWghJp2"
   },
   "source": [
    "\n",
    "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
    "\n",
    "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "5e2e4ede177a4eadb2d9be85e251b90b",
      "a27286426ab341a6959ddce80f09a308",
      "7eab8d36762f48ccbb3a1918eb2a8530",
      "f46c7d907b1e45b7a9752547fcdd3bfd",
      "70a2cd41889447fbadbb2c260dc5a668",
      "91527529e9544577801716e7ae086657",
      "953ea603c76a438183b0563170532367",
      "eba26cf3541049a2875b5759fde8561e"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1588967272930,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "Z474sSC6oe7A",
    "outputId": "290da90e-e404-4474-fd92-5aba2bdb4364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2e4ede177a4eadb2d9be85e251b90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6w8elb-58GJ"
   },
   "source": [
    "## 3.2. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7244,
     "status": "ok",
     "timestamp": 1588967278647,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "cKsH2sU0OCQA",
    "outputId": "af46d894-fae4-4a3a-c475-82557f89357d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  50\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1M296yz577fV"
   },
   "source": [
    "Just in case there are some longer test sentences, I'll set the maximum length to 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9748,
     "status": "ok",
     "timestamp": 1588967281468,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "2bBdb3pt8LuQ",
    "outputId": "4e5ab995-47be-40d9-8e5c-0dcd112f5dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  can #lighttherapy help with #sad or #depression? #altwaystoheal #healthy is !! \n",
      "Token IDs: tensor([  101,  2064,  1001,  2422, 20900,  2393,  2007,  1001,  6517,  2030,\n",
      "         1001,  6245,  1029,  1001, 12456, 14035,  3406, 20192,  2140,  1001,\n",
      "         7965,  2003,   999,   999,   102,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 100,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRp4O7D295d_"
   },
   "source": [
    "## 3.3. Training & Validation & Testing Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu0ao7p8rb06"
   },
   "source": [
    "Divide up dataset to 80% for training, 10% for validation and 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9252,
     "status": "ok",
     "timestamp": 1588967281474,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "GEgLpFVlo1Z-",
    "outputId": "bf2f4546-5fc7-469d-ae37-02fc7ba26744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,174 training samples\n",
      "  897 validation samples\n",
      "  897 testing samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "test_size = val_size - int(val_size/2)\n",
    "val_size = val_size - test_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "print('{:>5,} testing samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dD9i6Z2pG-sN"
   },
   "source": [
    "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGUqOCtgqGhP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bwa6Rts-02-"
   },
   "source": [
    "# 4. Train Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "## 4.1. BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sjzRT1V0zwm"
   },
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXYitPoE-cjH"
   },
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "192087a32f124ea29c01324ebdba47ed",
      "16977ca83b8b4225bb9442922f7360f1",
      "06687245516b46b5912394a48dde79ab",
      "e2386eb5f3fb4b42b84bea03f8920d49",
      "6d708c0aaa7b4bd8825924d6312053ef",
      "e29c828aa16243d58bfefdb818526eef",
      "671513bed81a45b2a5f6a2ff8a50d0e8",
      "b54b1490b803435fa49f50d9abb527a1",
      "c90917aa136347418070565640b74ff4",
      "5db542c36a254a24819c229abcdcf158",
      "f4709330809a40a3996a354937af9ffb",
      "479827ae3f3a45f3b490b8ab4789f7ac",
      "d0fe1a8145d643aeb266cc372e8f89f5",
      "796fd8d95569477fb3cb0946b4dd783e",
      "6a89c9acac014e92a85e7e33c0c85f9c",
      "58e846db4435455896f68430d2f269d3"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29887,
     "status": "ok",
     "timestamp": 1588967305426,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "gFsCTp_mporB",
    "outputId": "a6f67343-90d7-4067-98f8-911897079af1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192087a32f124ea29c01324ebdba47ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90917aa136347418070565640b74ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29453,
     "status": "ok",
     "timestamp": 1588967305428,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "8PIiVlDYCtSq",
    "outputId": "86f479de-7084-4f71-cd42-536f4cf04b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRWT-D4U_Pvx"
   },
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLs72DuMODJO"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 2, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RqfmWwUR_Sox"
   },
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pE5B99H5H2-W"
   },
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cQNvaZ9bnyy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNhRtWPXH9C3"
   },
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQTvJ1vRP7u4"
   },
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167721,
     "status": "ok",
     "timestamp": 1588967448925,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "6J-FYdx6nFE_",
    "outputId": "a36caa32-3464-402d-cf7f-6779d7a9db16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    225.    Elapsed: 0:00:13.\n",
      "  Batch    80  of    225.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    225.    Elapsed: 0:00:37.\n",
      "  Batch   160  of    225.    Elapsed: 0:00:50.\n",
      "  Batch   200  of    225.    Elapsed: 0:01:02.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    225.    Elapsed: 0:00:12.\n",
      "  Batch    80  of    225.    Elapsed: 0:00:25.\n",
      "  Batch   120  of    225.    Elapsed: 0:00:37.\n",
      "  Batch   160  of    225.    Elapsed: 0:00:49.\n",
      "  Batch   200  of    225.    Elapsed: 0:01:02.\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:02:24 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167179,
     "status": "ok",
     "timestamp": 1588967448927,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "6O_NbXFGMukX",
    "outputId": "6dac48dd-2984-4a29-841f-45474a2a2459"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:01:09</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0:01:09</td>\n",
       "      <td>0:00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.34         0.23           0.91       0:01:09         0:00:03\n",
       "2               0.16         0.21           0.93       0:01:09         0:00:03"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 166636,
     "status": "ok",
     "timestamp": 1588967448931,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "68xreA9JAmG5",
    "outputId": "4e9a6ed5-cdf5-42be-d9af-ca8455c74257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,3)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# 5. Performance On Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tg42jJqqM68F"
   },
   "source": [
    "### 5.1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mAN0LZBOOPVh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = test_dataset\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16lctEOyNFik"
   },
   "source": [
    "## 5.2. Evaluate on Test Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhR99IISNMg9"
   },
   "source": [
    "\n",
    "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 166432,
     "status": "ok",
     "timestamp": 1588967451929,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "Hba10sXR7Xi6",
    "outputId": "f6d43fad-384e-4b08-a7e7-1521d194e223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 897 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(test_size))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids,\n",
    "                      token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165881,
     "status": "ok",
     "timestamp": 1588967451930,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "oCYZa1lQ8Jn8",
    "outputId": "f38cf5b2-aca1-45a1-d969-6e6c6bb330dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_t = confusion_matrix(flat_true_labels, flat_predictions)\n",
    "\n",
    "num_classes = 2\n",
    "matrix_proportions = np.zeros((num_classes, num_classes))\n",
    "\n",
    "for i in range(0, num_classes):\n",
    "    matrix_proportions[i,:] = confusion_matrix_t[i,:]/float(confusion_matrix_t[i,:].sum())\n",
    "names=['0', '1']\n",
    "\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tick_params(labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 165040,
     "status": "ok",
     "timestamp": 1588967451931,
     "user": {
      "displayName": "Zhenguo CUI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7qfxzueazpDjdkELeMcCEVXH2r1Zl7Xljcmys=s64",
      "userId": "12627899431939335042"
     },
     "user_tz": -120
    },
    "id": "7F96WViDsZAo",
    "outputId": "c0f16fb3-8fe1-4cc0-c674-7bcc934ebd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       434\n",
      "           1       0.95      0.95      0.95       463\n",
      "\n",
      "    accuracy                           0.95       897\n",
      "   macro avg       0.95      0.95      0.95       897\n",
      "weighted avg       0.95      0.95      0.95       897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(flat_true_labels, flat_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUmsUOIv8EUO"
   },
   "source": [
    "# Appendix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2079Qyn8Mt8"
   },
   "source": [
    "## A1. Saving & Loading Fine-Tuned Model\n",
    "\n",
    "This first cell (taken from `run_glue.py` [here](https://github.com/huggingface/transformers/blob/35ff345fc9df9e777b27903f11fa213e4052595b/examples/run_glue.py#L495)) writes the model and tokenizer out to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ulTWaOr8QNY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-tjHkR7lc1I"
   },
   "source": [
    "Let's check out the file sizes, out of curiosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqMzI3VTCZo5"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=K ./model_save/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fr_bt2rFlgDn"
   },
   "source": [
    "The largest file is the model weights, at around 418 megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WUFUIQ8Cu8D"
   },
   "outputs": [],
   "source": [
    "!ls -l --block-size=M ./model_save/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzGKvOFAll_e"
   },
   "source": [
    "To save your model across Colab Notebook sessions, download it to your local machine, or ideally copy it to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Trr-A-POC18_"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive to this Notebook instance.\n",
    "from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxlZsafTC-V5"
   },
   "outputs": [],
   "source": [
    "# Copy the model files to a directory in your Google Drive.\n",
    "!cp -r ./model_save/ \"./drive/Shared drives/ChrisMcCormick.AI/Blog Posts/BERT Fine-Tuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0vstijw85SZ"
   },
   "source": [
    "The following functions will load the model back from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nskPzUM084zL"
   },
   "outputs": [],
   "source": [
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIWouvDrGVAi"
   },
   "source": [
    "## A.2. Weight Decay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f123ZAlF1OyW"
   },
   "source": [
    "The huggingface example includes the following code block for enabling weight decay, but the default decay rate is \"0.0\", so I moved this to the appendix.\n",
    "\n",
    "This block essentially tells the optimizer to not apply weight decay to the bias terms (e.g., $ b $ in the equation $ y = Wx + b $ ). Weight decay is a form of regularization--after calculating the gradients, we multiply them by, e.g., 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSMw0FrptiL"
   },
   "outputs": [],
   "source": [
    "# This code is taken from:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
    "\n",
    "# Don't apply weight decay to any parameters whose names include these tokens.\n",
    "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "# Separate the `weight` parameters from the `bias` parameters. \n",
    "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
    "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
    "optimizer_grouped_parameters = [\n",
    "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.1},\n",
    "    \n",
    "    # Filter for parameters which *do* include those.\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
    "# the names."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT HateSpeechDetection Augmented Training Dataset.ipynb",
   "provenance": [
    {
     "file_id": "13iuin5C8AsIGT3AcTqxjgX0YUOBqJ8vg",
     "timestamp": 1588966601570
    },
    {
     "file_id": "1ElosjJ4d_FexPNzWsZaG12Uuqqc8knEc",
     "timestamp": 1588965348043
    },
    {
     "file_id": "1on_UyDG8PmkrPhPzCNjemwyklIWHBnLB",
     "timestamp": 1588965163511
    },
    {
     "file_id": "1qCYemqVAzqxc9b7AWd4ZV3jzNIHokrJ8",
     "timestamp": 1588535863072
    },
    {
     "file_id": "1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX",
     "timestamp": 1588504671093
    },
    {
     "file_id": "1dcucJvUOx6kdopjhVIwIdpby6VXhnvns",
     "timestamp": 1575478354980
    },
    {
     "file_id": "1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO",
     "timestamp": 1575307876986
    },
    {
     "file_id": "1f_snPs--PVYgZJwT3GwjxqVALFJ0T2-y",
     "timestamp": 1556493831452
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06687245516b46b5912394a48dde79ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e29c828aa16243d58bfefdb818526eef",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d708c0aaa7b4bd8825924d6312053ef",
      "value": 433
     }
    },
    "16977ca83b8b4225bb9442922f7360f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "192087a32f124ea29c01324ebdba47ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06687245516b46b5912394a48dde79ab",
       "IPY_MODEL_e2386eb5f3fb4b42b84bea03f8920d49"
      ],
      "layout": "IPY_MODEL_16977ca83b8b4225bb9442922f7360f1"
     }
    },
    "479827ae3f3a45f3b490b8ab4789f7ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58e846db4435455896f68430d2f269d3",
      "placeholder": "​",
      "style": "IPY_MODEL_6a89c9acac014e92a85e7e33c0c85f9c",
      "value": " 440M/440M [00:09&lt;00:00, 44.2MB/s]"
     }
    },
    "58e846db4435455896f68430d2f269d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5db542c36a254a24819c229abcdcf158": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e2e4ede177a4eadb2d9be85e251b90b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7eab8d36762f48ccbb3a1918eb2a8530",
       "IPY_MODEL_f46c7d907b1e45b7a9752547fcdd3bfd"
      ],
      "layout": "IPY_MODEL_a27286426ab341a6959ddce80f09a308"
     }
    },
    "671513bed81a45b2a5f6a2ff8a50d0e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a89c9acac014e92a85e7e33c0c85f9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d708c0aaa7b4bd8825924d6312053ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "70a2cd41889447fbadbb2c260dc5a668": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "796fd8d95569477fb3cb0946b4dd783e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eab8d36762f48ccbb3a1918eb2a8530": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91527529e9544577801716e7ae086657",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70a2cd41889447fbadbb2c260dc5a668",
      "value": 231508
     }
    },
    "91527529e9544577801716e7ae086657": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "953ea603c76a438183b0563170532367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a27286426ab341a6959ddce80f09a308": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b54b1490b803435fa49f50d9abb527a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c90917aa136347418070565640b74ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4709330809a40a3996a354937af9ffb",
       "IPY_MODEL_479827ae3f3a45f3b490b8ab4789f7ac"
      ],
      "layout": "IPY_MODEL_5db542c36a254a24819c229abcdcf158"
     }
    },
    "d0fe1a8145d643aeb266cc372e8f89f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e2386eb5f3fb4b42b84bea03f8920d49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b54b1490b803435fa49f50d9abb527a1",
      "placeholder": "​",
      "style": "IPY_MODEL_671513bed81a45b2a5f6a2ff8a50d0e8",
      "value": " 433/433 [00:00&lt;00:00, 831B/s]"
     }
    },
    "e29c828aa16243d58bfefdb818526eef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eba26cf3541049a2875b5759fde8561e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46c7d907b1e45b7a9752547fcdd3bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eba26cf3541049a2875b5759fde8561e",
      "placeholder": "​",
      "style": "IPY_MODEL_953ea603c76a438183b0563170532367",
      "value": " 232k/232k [00:00&lt;00:00, 814kB/s]"
     }
    },
    "f4709330809a40a3996a354937af9ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_796fd8d95569477fb3cb0946b4dd783e",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0fe1a8145d643aeb266cc372e8f89f5",
      "value": 440473133
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
